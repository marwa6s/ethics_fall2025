---
title: 'Ethic Blog 1: Ethical Frameworks'
date: 2025-09-16
permalink: /posts/2025/09/blog-post-1/
tags:
  - Regulating AI
  - Ethics
  - Harvard Study
---
Studies show that AI can already persuade people better than expert negotiators. As AI becomes more common in business and finance, it creates new risks that our current laws and institutions are not ready to handle.

**New Article**  
[How To Regulate AI](https://news.harvard.edu/gazette/story/2025/09/how-to-regulate-artificial-intelligence-ai/)

As a Black Muslim woman artist living in the West, I chose to read the Harvard article “How to Regulate AI” by Sy Boles because AI is shaping creative work, jobs, and public life in ways that affect communities like mine. At first, AI regulation sounded distant from my daily experience, but I realized it is directly connected to how my identity is treated in digital spaces. When technology is created without diverse voices, it often repeats old biases instead of challenging them.

The article raises ethical concerns about AI, especially around bias, transparency, and accountability. AI learns from data, and if the data excludes or stereotypes people, the system can harm Black and Muslim communities. Many AI tools also operate like “black boxes,” so people do not understand how decisions are made or how their information is used. Another issue is accountability if an AI system discriminates or causes damage, it is unclear who should be responsible. The tension between public good and corporate profit is also important, because companies often move faster than society can protect vulnerable communities.

The stakeholders in this issue include everyday users, artists whose work becomes training data, tech companies building these systems, and governments making policy. But many people are left out of these discussions, such as marginalized creators and communities with limited access to technology. These groups are often impacted first and worst, yet their concerns are rarely heard.

Using ethical frameworks helps show what “right” action might look like. A utilitarian approach supports regulation if it reduces harm and benefits the majority. A deontological view would argue that protecting rights—such as equality and privacy—is a duty, even if it slows innovation. A justice-oriented approach focuses on fairness and including those most affected by bias in creating ethical rules.

For me, AI regulation could protect my art from being used without consent and reduce bias in systems that label or judge people based on identity. It could make digital spaces safer and more inclusive for Black Muslim women and other marginalized creators.

This assignment helped me see that AI ethics is not just about technology; it is about dignity, representation, and who gets to shape the future. Regulation is not meant to block progress, but to make sure progress includes all of us.
